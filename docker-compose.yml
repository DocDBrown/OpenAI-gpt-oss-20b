# docker-compose.yml
services:
  llama:
    image: docdbrown/gpt-oss-20b:1.0.0
    platform: linux/arm64
    pull_policy: always
    container_name: gpt-oss-20b
    restart: unless-stopped
    ports:
      - "8080:8080"
    command:
      [
        "-m", "/models/gpt-oss-20b-Q5_K_M.gguf",
        "--host", "0.0.0.0",
        "--port", "8080",
        "-c", "0",
        "-n", "512",
        "--jinja",
        "--n-gpu-layers", "0"
      ]
